# Notes on Supervised Machine Learning: Regression and Classification

## Week 1

* supervised learning: trains on labeled data, more widely used. Maps x -> y outcomes.
* unsupervised learning: less widely used, looks for patterns in unlabeled data

Supervised learning
* regression: predict infinite possible outputs
* classification: discrete, finite set out possible outputs

Unsupervised learning
* Clustering unlabeled N-dimensional data into groups
* Anomaly detection
* dimensionality reduction


### Supervised learning
$x \to [f] \to y$

We map inputs $x^i$ to outputs (target variable) $y^i$ for training example $i$ with $m$ training examples.

Cost function example: squared error cost function

$J(w,b) = \frac{1}{2 m} \sum_{i=1}^m (\hat{y}_i - y_i)^2$

with the prediction $\hat{y}^i = f(w,b)^i$.

## Week 2


## Week 3

